{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "daddf22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9857142857142858\n",
      "[2]\n",
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, model_selection, neighbors\n",
    "\n",
    "df = pd.read_csv('breast_cancer.csv')\n",
    "df.replace('?', -99999, inplace=True)\n",
    "df.drop(['id'], inplace=True, axis=1)\n",
    "\n",
    "X = np.array(df.drop(['class'], axis=1))\n",
    "y = np.array(df['class'])\n",
    "#X = preprocessing.scale(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n",
    "clf = neighbors.KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "\n",
    "example_measures = np.array([4, 2, 1, 1, 1, 2, 3, 2, 1])\n",
    "example_measures = example_measures.reshape(1, -1)\n",
    "example_measures_1 = np.array([[4, 2, 1, 1, 1, 2, 3, 2, 1], [5, 2, 1, 2, 1, 2, 1, 2, 1]])\n",
    "example_measures_1 = example_measures_1.reshape(len(example_measures_1), -1)\n",
    "prediction_1 = clf.predict(example_measures_1)\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)\n",
    "print(prediction_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e965379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8284271247461903\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "plot1 = [1, 3]\n",
    "plot2 = [3, 5]\n",
    "\n",
    "euclidean_distance = sqrt((plot1[0]-plot2[0])**2 + (plot1[1]-plot2[1])**2)\n",
    "print(euclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e392d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data types and shapes:\n",
      "X_train shape: (559, 9)\n",
      "X_train dtype: object\n",
      "Sample X_train values: [3 1 1 3 8 '1' 5 8 1]\n",
      "y_train shape: (559,)\n",
      "y_train dtype: int64\n",
      "Sample y_train values: [2 2 4 2 2]\n",
      "\n",
      "After conversion:\n",
      "X_train_numeric dtype: float64\n",
      "Sample X_train_numeric values: [3. 1. 1. 3. 8. 1. 5. 8. 1.]\n",
      "\n",
      "Manual KNN Implementation Results:\n",
      "========================================\n",
      "Manual KNN Accuracy: 0.9857\n",
      "Manual KNN prediction for single example: [2]\n",
      "Manual KNN prediction for multiple examples: [2 2]\n",
      "\n",
      "Comparison with sklearn:\n",
      "sklearn accuracy: 0.9857\n",
      "Manual KNN accuracy: 0.9857\n",
      "Difference: 0.0000\n",
      "Manual KNN Accuracy: 0.9857\n",
      "Manual KNN prediction for single example: [2]\n",
      "Manual KNN prediction for multiple examples: [2 2]\n",
      "\n",
      "Comparison with sklearn:\n",
      "sklearn accuracy: 0.9857\n",
      "Manual KNN accuracy: 0.9857\n",
      "Difference: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Manual K-Nearest Neighbors Implementation\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# First, let's check and fix the data types\n",
    "print(\"Checking data types and shapes:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_train dtype: {X_train.dtype}\")\n",
    "print(f\"Sample X_train values: {X_train[0]}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_train dtype: {y_train.dtype}\")\n",
    "print(f\"Sample y_train values: {y_train[:5]}\")\n",
    "\n",
    "# Convert data to float if needed\n",
    "X_train_numeric = X_train.astype(float)\n",
    "X_test_numeric = X_test.astype(float)\n",
    "y_train_numeric = y_train\n",
    "y_test_numeric = y_test\n",
    "\n",
    "print(f\"\\nAfter conversion:\")\n",
    "print(f\"X_train_numeric dtype: {X_train_numeric.dtype}\")\n",
    "print(f\"Sample X_train_numeric values: {X_train_numeric[0]}\")\n",
    "\n",
    "class ManualKNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"Store the training data\"\"\"\n",
    "        self.X_train = X_train.astype(float)\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def euclidean_distance(self, point1, point2):\n",
    "        \"\"\"Calculate euclidean distance between two points\"\"\"\n",
    "        return np.sqrt(np.sum((point1 - point2) ** 2))\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict the class labels for the test data\"\"\"\n",
    "        X_test = X_test.astype(float)\n",
    "        predictions = []\n",
    "        \n",
    "        for test_point in X_test:\n",
    "            # Calculate distances from test point to all training points\n",
    "            distances = []\n",
    "            for i, train_point in enumerate(self.X_train):\n",
    "                distance = self.euclidean_distance(test_point, train_point)\n",
    "                distances.append((distance, self.y_train[i]))\n",
    "            \n",
    "            # Sort by distance and get k nearest neighbors\n",
    "            distances.sort(key=lambda x: x[0])\n",
    "            k_nearest = distances[:self.k]\n",
    "            \n",
    "            # Get the labels of k nearest neighbors\n",
    "            k_nearest_labels = [label for distance, label in k_nearest]\n",
    "            \n",
    "            # Vote for the most common class\n",
    "            most_common = Counter(k_nearest_labels).most_common(1)\n",
    "            predictions.append(most_common[0][0])\n",
    "            \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"Calculate accuracy of predictions\"\"\"\n",
    "        predictions = self.predict(X_test)\n",
    "        accuracy = np.mean(predictions == y_test)\n",
    "        return accuracy\n",
    "\n",
    "# Test the manual KNN implementation\n",
    "print(\"\\nManual KNN Implementation Results:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create and train the manual KNN classifier\n",
    "manual_knn = ManualKNN(k=5)\n",
    "manual_knn.fit(X_train_numeric, y_train_numeric)\n",
    "\n",
    "# Make predictions\n",
    "manual_predictions = manual_knn.predict(X_test_numeric)\n",
    "manual_accuracy = manual_knn.score(X_test_numeric, y_test_numeric)\n",
    "\n",
    "print(f\"Manual KNN Accuracy: {manual_accuracy:.4f}\")\n",
    "\n",
    "# Test with the same examples as before\n",
    "example_prediction = manual_knn.predict(example_measures)\n",
    "example_prediction_1 = manual_knn.predict(example_measures_1)\n",
    "\n",
    "print(f\"Manual KNN prediction for single example: {example_prediction}\")\n",
    "print(f\"Manual KNN prediction for multiple examples: {example_prediction_1}\")\n",
    "\n",
    "# Compare with sklearn results\n",
    "print(\"\\nComparison with sklearn:\")\n",
    "print(f\"sklearn accuracy: {accuracy:.4f}\")\n",
    "print(f\"Manual KNN accuracy: {manual_accuracy:.4f}\")\n",
    "print(f\"Difference: {abs(accuracy - manual_accuracy):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a70746b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-by-step KNN demonstration:\n",
      "==================================================\n",
      "Test sample: [3. 1. 1. 1. 2. 1. 1. 1. 1.]\n",
      "\n",
      "K=5 nearest neighbors:\n",
      "  Neighbor 1: Distance=0.0000, Label=2, Training Index=27\n",
      "  Neighbor 2: Distance=0.0000, Label=2, Training Index=48\n",
      "  Neighbor 3: Distance=0.0000, Label=2, Training Index=70\n",
      "  Neighbor 4: Distance=0.0000, Label=2, Training Index=169\n",
      "  Neighbor 5: Distance=0.0000, Label=2, Training Index=251\n",
      "\n",
      "Vote count: {2: 5}\n",
      "Predicted class: 2\n",
      "Actual class: 2\n",
      "\n",
      "Algorithm Summary:\n",
      "1. Calculate distance from test point to all 559 training points\n",
      "2. Sort distances and select 5 nearest neighbors\n",
      "3. Take majority vote among the 5 nearest neighbor labels\n",
      "4. Assign the most common class as the prediction\n"
     ]
    }
   ],
   "source": [
    "# Detailed demonstration of how KNN works step by step\n",
    "print(\"Step-by-step KNN demonstration:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Let's trace through one prediction to show how it works\n",
    "test_sample = X_test_numeric[0]  # Take the first test sample\n",
    "print(f\"Test sample: {test_sample}\")\n",
    "\n",
    "# Calculate distances to all training points\n",
    "distances_demo = []\n",
    "for i, train_point in enumerate(X_train_numeric):\n",
    "    distance = manual_knn.euclidean_distance(test_sample, train_point)\n",
    "    distances_demo.append((distance, y_train_numeric[i], i))\n",
    "\n",
    "# Sort by distance\n",
    "distances_demo.sort(key=lambda x: x[0])\n",
    "\n",
    "# Show the 5 nearest neighbors\n",
    "print(f\"\\nK={manual_knn.k} nearest neighbors:\")\n",
    "for i in range(manual_knn.k):\n",
    "    dist, label, idx = distances_demo[i]\n",
    "    print(f\"  Neighbor {i+1}: Distance={dist:.4f}, Label={label}, Training Index={idx}\")\n",
    "\n",
    "# Count votes\n",
    "k_nearest_labels = [label for distance, label, idx in distances_demo[:manual_knn.k]]\n",
    "vote_count = Counter(k_nearest_labels)\n",
    "print(f\"\\nVote count: {dict(vote_count)}\")\n",
    "prediction = vote_count.most_common(1)[0][0]\n",
    "print(f\"Predicted class: {prediction}\")\n",
    "print(f\"Actual class: {y_test_numeric[0]}\")\n",
    "\n",
    "# Show the algorithm components\n",
    "print(f\"\\nAlgorithm Summary:\")\n",
    "print(f\"1. Calculate distance from test point to all {len(X_train_numeric)} training points\")\n",
    "print(f\"2. Sort distances and select {manual_knn.k} nearest neighbors\")\n",
    "print(f\"3. Take majority vote among the {manual_knn.k} nearest neighbor labels\")\n",
    "print(f\"4. Assign the most common class as the prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dbacd9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing different k values:\n",
      "==============================\n",
      "k= 1: Accuracy = 1.0000\n",
      "k= 3: Accuracy = 0.9929\n",
      "k= 5: Accuracy = 0.9857\n",
      "k= 7: Accuracy = 0.9857\n",
      "k= 9: Accuracy = 0.9786\n",
      "k=11: Accuracy = 0.9714\n",
      "k=15: Accuracy = 0.9786\n",
      "k=20: Accuracy = 0.9786\n",
      "\n",
      "Best k value: 1 with accuracy: 1.0000\n",
      "\n",
      "Choosing k:\n",
      "- Small k (like 1): More sensitive to noise, may overfit\n",
      "- Large k: Smoother decision boundary, may underfit\n",
      "- Odd k values help avoid ties in binary classification\n",
      "- Rule of thumb: k = sqrt(n_samples), here sqrt(559) ≈ 23\n"
     ]
    }
   ],
   "source": [
    "# Testing different k values to see their impact\n",
    "print(\"Testing different k values:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9, 11, 15, 20]\n",
    "accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = ManualKNN(k=k)\n",
    "    knn.fit(X_train_numeric, y_train_numeric)\n",
    "    accuracy = knn.score(X_test_numeric, y_test_numeric)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"k={k:2d}: Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# Find the best k\n",
    "best_k_idx = np.argmax(accuracies)\n",
    "best_k = k_values[best_k_idx]\n",
    "best_accuracy = accuracies[best_k_idx]\n",
    "\n",
    "print(f\"\\nBest k value: {best_k} with accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Show some theory about choosing k\n",
    "print(f\"\\nChoosing k:\")\n",
    "print(f\"- Small k (like 1): More sensitive to noise, may overfit\")\n",
    "print(f\"- Large k: Smoother decision boundary, may underfit\")\n",
    "print(f\"- Odd k values help avoid ties in binary classification\")\n",
    "print(f\"- Rule of thumb: k = sqrt(n_samples), here sqrt({len(X_train_numeric)}) ≈ {int(np.sqrt(len(X_train_numeric)))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
